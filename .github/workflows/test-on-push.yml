name: Test and Coverage on Push

on:
  push:
    branches:
      - main
      - development
      - 'feature/**'
      - 'hotfix/**'
      - 'release/**'
    paths-ignore:
      # Documentation and non-code files
      - '**.md'
      - 'docs/**'
      - 'examples/**'
      - 'scripts/**'
      
      # Generated files and build artifacts
      - 'coverage/**'
      - '.nyc_output/**'
      - 'node_modules/**'
      - '*.log'
      
      # Note: .github/** is intentionally NOT ignored to allow workflow changes to trigger tests
  
  # Manual trigger for testing
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of test to run'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - quick
          - coverage-only

permissions:
  issues: write
  contents: read

jobs:
  test-and-coverage:
    runs-on: ubuntu-latest
    
    steps:
      # 0. Debug workflow trigger
      - name: Debug workflow trigger
        run: |
          echo "ğŸ” Workflow Debug Information"
          echo "============================="
          echo "Event: ${{ github.event_name }}"
          echo "Ref: ${{ github.ref }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "SHA: ${{ github.sha }}"
          echo "Actor: ${{ github.actor }}"
          echo "Repository: ${{ github.repository }}"
          echo "Workflow: ${{ github.workflow }}"
          echo "Triggered by: ${{ github.event.head_commit.message || 'Manual trigger' }}"
          echo "============================="

      # 1. Checkout the repository
      - name: Checkout code
        uses: actions/checkout@v4

      # 2. Set up Node.js
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.17.0'
          cache: 'npm'

      # 3. Install system dependencies
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y bc lcov

      # 3.5. Ensure required labels exist
      - name: Ensure required labels exist
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const labels = [
              { name: 'test-issues', color: 'd73a4a', description: 'Issues related to test failures or coverage' },
              { name: 'automated', color: '0366d6', description: 'Automatically created issues' },
              { name: 'needs-attention', color: 'fbca04', description: 'Issues that need immediate attention' }
            ];
            
            for (const label of labels) {
              try {
                await github.rest.issues.createLabel({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  name: label.name,
                  color: label.color,
                  description: label.description
                });
                console.log(`Created label: ${label.name}`);
              } catch (error) {
                if (error.status === 422) {
                  console.log(`Label ${label.name} already exists`);
                } else {
                  console.log(`Error with label ${label.name}:`, error.message);
                }
              }
            }

      # 5. Install dependencies
      - name: Install dependencies
        run: npm ci

      # 6. Generate JSDoc documentation (test)
      - name: Test JSDoc generation
        id: jsdoc-test
        run: |
          echo "ğŸ” Testing JSDoc documentation generation..."
          echo "Command: npx jsdoc -c jsdoc.conf.json"
          
          # Test JSDoc generation by running it and capturing output
          # We'll clean up the generated files afterwards
          if npx jsdoc -c jsdoc.conf.json 2>&1; then
            echo "âœ… JSDoc generation test passed!"
            echo "ğŸ“š All JSDoc tags are properly formatted"
            
            # Clean up generated documentation files
            if [ -d "docs" ]; then
              echo "ğŸ§¹ Cleaning up generated documentation files..."
              rm -rf docs/*
              echo "âœ… Documentation files cleaned up"
            fi
          else
            echo "âŒ JSDoc generation test failed!"
            echo "ğŸ” Check for missing @returns values, invalid tags, or syntax errors"
            echo "ğŸ’¡ Common issues:"
            echo "   - Missing @returns values"
            echo "   - Invalid JSDoc syntax"
            echo "   - Missing parameter descriptions"
            exit 1
          fi
          
          echo "JSDoc test completed"

      # 7. Run tests with coverage
      - name: Run tests with coverage
        id: test-run
        run: |
          echo "Running test suite with coverage..."
          echo "Test command: npx jest --coverage --watchAll=false --ci --verbose --json --outputFile=test-results.json"
          
          # Run tests with coverage and JSON output
          npx jest --coverage --watchAll=false --ci --verbose --json --outputFile=test-results.json || exit_code=$?
          
          # Check if tests failed
          if [ $? -eq 0 ]; then
            echo "âœ… All tests passed successfully!"
            echo "ğŸ“Š Coverage report generated"
            echo "ğŸ“‹ Test results saved to test-results.json"
          else
            echo "âŒ Some tests failed!"
            echo "ğŸ“Š Coverage report may be incomplete due to test failures"
            echo "ğŸ“‹ Test results saved to test-results.json for analysis"
            exit 1
          fi
          
          echo "Tests completed"

      # 7.1. Handle JSDoc test failures
      - name: Handle JSDoc Test Failures
        if: failure() && steps.jsdoc-test.outcome == 'failure'
        run: |
          echo "âŒ JSDoc generation test failed!"
          echo "ğŸ“‹ JSDoc Test Results Summary"
          echo "=============================="
          echo "ğŸš« Workflow will not proceed to unit tests"
          echo "ğŸ” Check the JSDoc test logs above for detailed failure information"
          echo "ğŸ’¡ Fix the JSDoc issues and re-run the workflow"
          
          echo ""
          echo "ğŸ“Š Common JSDoc Issues:"
          echo "======================="
          echo "1. Missing @returns values (e.g., '@returns' without description)"
          echo "2. Invalid JSDoc syntax or malformed tags"
          echo "3. Missing parameter descriptions"
          echo "4. Incorrect type annotations"
          
          echo ""
          echo "ğŸ” To fix JSDoc issues:"
          echo "1. Check the 'Test JSDoc generation' step logs above"
          echo "2. Look for specific error messages about missing @returns values"
          echo "3. Fix the JSDoc comments in the mentioned files"
          echo "4. Re-run the workflow to verify fixes"

      # 7.2. Handle unit test failures
      - name: Handle Unit Test Failures
        if: failure() && steps.test-run.outcome == 'failure'
        run: |
          echo "âŒ Unit test execution failed!"
          echo "ğŸ“‹ Test Results Summary"
          echo "========================"
          echo "ğŸš« Workflow will not proceed to coverage analysis"
          echo "ğŸ” Check the test logs above for detailed failure information"
          echo "ğŸ’¡ Fix the failing tests and re-run the workflow"
          
          # Try to extract test failure summary from Jest output
          echo ""
          echo "ğŸ“Š Test Failure Analysis:"
          echo "=========================="
          
          # Look for Jest test results in the logs
          if [ -f "test-results.json" ]; then
            echo "ğŸ“‹ Detailed test results available in test-results.json"
            cat test-results.json | jq -r '.testResults[] | "\(.name): \(.status) (\(.assertionResults | length) tests)"' 2>/dev/null || echo "Could not parse test results"
          fi
          
          echo ""
          echo "ğŸ” To see detailed test failures:"
          echo "1. Click on the 'Run tests with coverage' step above"
          echo "2. Look for lines starting with 'âŒ FAIL' or 'âœ•'"
          echo "3. Each failure shows the test suite name and specific test case"
          echo "4. Full error details and stack traces are shown below each failure"

      # 7. Coverage report status
      - name: Coverage report status
        if: success() # Only show coverage if tests passed
        run: |
          echo "ğŸ“Š Checking coverage report status..."
          if [ -d "coverage" ]; then
            echo "âœ… Coverage directory found"
            ls -la coverage/
          else
            echo "âš ï¸ No coverage directory found"
          fi

      # 8. Upload test results (always upload, even on failure)
      - name: Upload test results
        if: always() # Always upload test results for analysis
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            test-results.json
          retention-days: 30

      # 9. Upload coverage reports to GitHub
      - name: Upload coverage reports
        if: success() # Only upload coverage if tests passed
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: |
            coverage/
            .nyc_output/
          retention-days: 30

      # 10. Check coverage percentage
      - name: Check coverage percentage
        if: success() # Only check coverage if tests passed
        id: coverage-check
        run: |
          echo "ğŸ“Š Analyzing coverage reports..."
          
          if [ -f "coverage/lcov.info" ]; then
            echo "ğŸ“ˆ LCOV coverage file found"
            
            # Extract coverage percentages from lcov.info using proper parsing
            if command -v lcov >/dev/null 2>&1; then
              # Use lcov tool if available
              COVERAGE_SUMMARY=$(lcov --summary coverage/lcov.info 2>/dev/null | grep "lines" | head -1)
              if [ -n "$COVERAGE_SUMMARY" ]; then
                COVERAGE_PERCENT=$(echo "$COVERAGE_SUMMARY" | grep -o '[0-9.]*%' | head -1 | sed 's/%//')
                echo "coverage_percent=$COVERAGE_PERCENT" >> $GITHUB_OUTPUT
                echo "ğŸ“Š Coverage: $COVERAGE_PERCENT% (from lcov tool)"
              else
                echo "coverage_percent=0" >> $GITHUB_OUTPUT
                echo "âš ï¸ Could not parse lcov coverage"
              fi
            else
              # Fallback: parse lcov.info manually for line coverage
              TOTAL_LINES=$(grep -c "^LF:" coverage/lcov.info 2>/dev/null || echo "0")
              COVERED_LINES=$(grep -c "^LH:" coverage/lcov.info 2>/dev/null || echo "0")
              
              if [ "$TOTAL_LINES" -gt 0 ] && [ "$COVERED_LINES" -ge 0 ]; then
                COVERAGE_PERCENT=$(echo "scale=1; $COVERED_LINES * 100 / $TOTAL_LINES" | bc -l 2>/dev/null || echo "0")
                echo "coverage_percent=$COVERAGE_PERCENT" >> $GITHUB_OUTPUT
                echo "ğŸ“Š Coverage: $COVERAGE_PERCENT% (lines: $COVERED_LINES/$TOTAL_LINES)"
              else
                echo "coverage_percent=0" >> $GITHUB_OUTPUT
                echo "âš ï¸ Could not calculate line coverage"
              fi
            fi
          else
            echo "coverage_percent=0" >> $GITHUB_OUTPUT
            echo "âš ï¸ No coverage file found"
          fi
          
          # Also check for Jest coverage summary if available
          if [ -f "coverage/coverage-summary.json" ]; then
            echo "ğŸ“Š Jest coverage summary found"
            if command -v jq >/dev/null 2>&1; then
              JEST_COVERAGE=$(jq -r '.total.lines.pct' coverage/coverage-summary.json 2>/dev/null)
              if [ "$JEST_COVERAGE" != "null" ] && [ "$JEST_COVERAGE" != "" ]; then
                echo "ğŸ“Š Jest Coverage: $JEST_COVERAGE%"
                # Use Jest coverage if it's available and higher
                if [ -n "$JEST_COVERAGE" ] && (( $(echo "$JEST_COVERAGE > 0" | bc -l 2>/dev/null || echo "0") )); then
                  echo "coverage_percent=$JEST_COVERAGE" >> $GITHUB_OUTPUT
                  echo "ğŸ“Š Using Jest coverage: $JEST_COVERAGE%"
                fi
              fi
            fi
          fi

      # 10.1. Display coverage report in summary
      - name: Display coverage report
        if: success() # Only display coverage if tests passed
        run: |
          echo "## ğŸ“Š Coverage Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "coverage/lcov.info" ]; then
            echo "### ğŸ“ˆ LCOV Coverage Summary" >> $GITHUB_STEP_SUMMARY
            
            # Try to use lcov tool if available
            if command -v lcov >/dev/null 2>&1; then
              echo "```" >> $GITHUB_STEP_SUMMARY
              lcov --summary coverage/lcov.info 2>/dev/null | head -20 >> $GITHUB_STEP_SUMMARY
              echo "```" >> $GITHUB_STEP_SUMMARY
            else
              echo "**Coverage files available:**" >> $GITHUB_STEP_SUMMARY
              echo "- `coverage/lcov.info` - Line coverage data" >> $GITHUB_STEP_SUMMARY
              echo "- `coverage/lcov-report/index.html` - HTML report" >> $GITHUB_STEP_SUMMARY
              echo "- `coverage/coverage-summary.json` - JSON summary" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          if [ -f "coverage/coverage-summary.json" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ğŸ“Š Jest Coverage Summary" >> $GITHUB_STEP_SUMMARY
            echo "```json" >> $GITHUB_STEP_SUMMARY
            cat coverage/coverage-summary.json | jq -r '.total | "Statements: \(.statements.pct)% | Branches: \(.branches.pct)% | Functions: \(.functions.pct)% | Lines: \(.lines.pct)%"' >> $GITHUB_STEP_SUMMARY
            echo "```" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ“ **Coverage Artifacts**: Coverage reports are available as workflow artifacts" >> $GITHUB_STEP_SUMMARY

      # 11. Create test summary
      - name: Create test summary
        if: always()
        run: |
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # JSDoc test results
          if [ "${{ steps.jsdoc-test.outcome }}" == "success" ]; then
            echo "âœ… **JSDoc**: Documentation generation test passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **JSDoc**: Documentation generation test failed" >> $GITHUB_STEP_SUMMARY
            echo "ğŸ’¡ **Action Required**: Fix JSDoc issues before running unit tests" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Unit test results
          if [ "${{ steps.test-run.outcome }}" == "success" ]; then
            echo "âœ… **Unit Tests**: All tests passed successfully" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "ğŸ“Š **Coverage**: ${{ steps.coverage-check.outputs.coverage_percent }}%" >> $GITHUB_STEP_SUMMARY
            
            if [ "${{ steps.coverage-check.outcome }}" == "success" ] && (( $(echo "${{ steps.coverage-check.outputs.coverage_percent }} < 100" | bc -l 2>/dev/null || echo "0") )); then
              echo "âš ï¸ **Warning**: Coverage is below 100%" >> $GITHUB_STEP_SUMMARY
            else
              echo "ğŸ¯ **Coverage**: 100% coverage achieved!" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âŒ **Unit Tests**: Some tests failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "ğŸš« **Coverage**: Coverage analysis skipped due to test failures" >> $GITHUB_STEP_SUMMARY
            echo "ğŸ’¡ **Action Required**: Fix failing tests before analyzing coverage" >> $GITHUB_STEP_SUMMARY
            
            # Try to show specific test failures if test-results.json exists
            if [ -f "test-results.json" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "ğŸ” **Test Failure Details**: Download 'test-results' artifact for complete analysis" >> $GITHUB_STEP_SUMMARY
              echo "ğŸ“‹ **Quick Summary**: Check the 'Run tests with coverage' step logs above" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ” **Details**: Check the logs above for more information" >> $GITHUB_STEP_SUMMARY

      # 11. Comment on PR if this is a PR
      - name: Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('## Test Results Summary')
            );
            
            const testStatus = '${{ steps.test-run.outcome }}' === 'success' ? 'âœ… PASSED' : 'âŒ FAILED';
            const coveragePercent = '${{ steps.coverage-check.outputs.coverage_percent }}';
            const coverageStatus = parseFloat(coveragePercent) >= 100 ? 'ğŸ¯ 100%' : `âš ï¸ ${coveragePercent}%`;
            
            const commentBody = `## ğŸ§ª Test Results for Push
            
            **Status**: ${testStatus}
            **Coverage**: ${coverageStatus}
            
            **Details**: [View full workflow run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            
            ---
            *This comment was automatically generated by the test workflow*`;
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: commentBody
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: commentBody
              });
            }

      # 12. Notify on failure or low coverage
      - name: Notify on issues
        if: always() && (steps.jsdoc-test.outcome == 'failure' || steps.test-run.outcome == 'failure' || steps.coverage-check.outputs.coverage_percent < 100)
        uses: actions/github-script@v7
        with:
          script: |
            const issueTitle = `Test Issues Detected - ${context.sha.substring(0, 7)}`;
            const issueBody = `## ğŸš¨ Test Issues Detected
            
            **Commit**: ${context.sha}
            **Branch**: ${context.ref}
            **Author**: @${context.actor}
            **Workflow**: [${context.workflow}](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            
            ### Issues Found:
            ${'${{ steps.jsdoc-test.outcome }}' === 'failure' ? '- âŒ **JSDoc Failed**: Documentation generation test failed' : ''}
            ${'${{ steps.test-run.outcome }}' === 'failure' ? '- âŒ **Tests Failed**: Some tests are failing' : ''}
            ${parseFloat('${{ steps.coverage-check.outputs.coverage_percent }}') < 100 ? `- âš ï¸ **Low Coverage**: Current coverage is ${{ steps.coverage-check.outputs.coverage_percent }}% (target: 100%)` : ''}
            
            ### Required Actions:
            ${'${{ steps.jsdoc-test.outcome }}' === 'failure' ? '- [ ] Fix JSDoc issues (missing @returns values, invalid syntax)' : ''}
            ${'${{ steps.test-run.outcome }}' === 'failure' ? '- [ ] Fix failing tests' : ''}
            ${parseFloat('${{ steps.coverage-check.outputs.coverage_percent }}') < 100 ? '- [ ] Improve test coverage to 100%' : ''}
            - [ ] Re-run tests to verify fixes
            
            ---
            *This issue was automatically created by the test workflow*`;
            
            // Check if issue already exists
            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: ['test-issues', 'automated']
            });
            
            const existingIssue = issues.find(issue => 
              issue.title === issueTitle && 
              issue.body.includes(context.sha.substring(0, 7))
            );
            
            if (!existingIssue) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: issueTitle,
                body: issueBody,
                labels: ['test-issues', 'automated', 'needs-attention'],
                assignees: [context.actor]
              });
            }

      # 13. Final status
      - name: Final status
        if: always()
        run: |
          if [ "${{ steps.jsdoc-test.outcome }}" == "success" ] && [ "${{ steps.test-run.outcome }}" == "success" ]; then
            if [ "${{ steps.coverage-check.outputs.coverage_percent }}" == "100" ]; then
              echo "ğŸ‰ All checks passed! JSDoc, tests successful and 100% coverage achieved."
            else
              echo "âœ… JSDoc and tests passed but coverage is below 100% (${{ steps.coverage-check.outputs.coverage_percent }}%)"
            fi
          else
            if [ "${{ steps.jsdoc-test.outcome }}" != "success" ]; then
              echo "âŒ JSDoc generation test failed. Please check the logs above for details."
              echo "ğŸ’¡ Fix JSDoc issues before running unit tests."
            fi
            if [ "${{ steps.test-run.outcome }}" != "success" ]; then
              echo "âŒ Unit tests failed. Please check the logs above for details."
              echo "ğŸ’¡ Coverage analysis was skipped due to test failures."
            fi
          fi
